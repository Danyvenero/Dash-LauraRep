"""
Módulo de Analytics Avançados para Dashboard WEG
Implementa análises estatísticas, gaps de oportunidade, alertas e insights inteligentes
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union
from scipy import stats
import warnings
from utils.db import SENTINEL_ALL

warnings.filterwarnings('ignore')

class AdvancedAnalytics:
    """Classe para Analytics Avançados com fundamentação estatística"""
    
    def __init__(self, vendas_df: pd.DataFrame = None, cotacoes_df: pd.DataFrame = None):
        """
        Inicializa o analisador com dados opcionais
        
        Args:
            vendas_df: DataFrame de vendas (opcional)
            cotacoes_df: DataFrame de cotações (opcional)
        """
        self.current_date = datetime.now()
        self.confidence_level = 0.95  # Nível de confiança padrão 95%
        self.vendas_df = vendas_df
        self.cotacoes_df = cotacoes_df
        
    # ==========================================
    # MÉTODOS SIMPLIFICADOS PARA DASHBOARD
    # ==========================================
    
    def calculate_opportunity_gaps(self, vendas_df: pd.DataFrame = None, cotacoes_df: pd.DataFrame = None) -> pd.DataFrame:
        """
        Versão simplificada para análise de gaps de oportunidade
        Analisa todos os produtos e identifica oportunidades baseado em padrões de compra
        
        Args:
            vendas_df: DataFrame de vendas (usa self.vendas_df se não fornecido)
            cotacoes_df: DataFrame de cotações (usa self.cotacoes_df se não fornecido)
            
        Returns:
            DataFrame com análise de gaps por produto
        """
        # Usa DataFrames armazenados se não fornecidos
        vendas_data = vendas_df if vendas_df is not None else self.vendas_df
        cotacoes_data = cotacoes_df if cotacoes_df is not None else self.cotacoes_df
        
        if vendas_data is None or vendas_data.empty:
            return pd.DataFrame({
                'produto': ['Nenhum produto'],
                'gap_score': [0],
                'gap_category': ['Sem dados'],
                'current_revenue': [0],
                'potential_revenue': [0],
                'cliente_count': [0]
            })
        
        print("🎯 Calculando gaps de oportunidade para todos os produtos")
        
        try:
            # Agrupa vendas por produto
            produto_stats = vendas_data.groupby('produto').agg({
                'valor_liquido': ['sum', 'mean', 'count'],
                'cod_cliente': 'nunique'
            }).round(2)
            
            produto_stats.columns = ['receita_total', 'receita_media', 'vendas_count', 'cliente_count']
            produto_stats = produto_stats.reset_index()
            
            # Calcula estatísticas gerais
            receita_mean = produto_stats['receita_total'].mean()
            receita_std = produto_stats['receita_total'].std()
            
            # Calcula gap score baseado em desvio padrão da receita
            produto_stats['gap_score'] = np.where(
                produto_stats['receita_total'] > 0,
                ((produto_stats['receita_total'] - receita_mean) / receita_std * 25 + 50).clip(0, 100),
                0
            )
            
            # Calcula receita potencial (estimativa baseada no percentil 75)
            receita_p75 = produto_stats['receita_total'].quantile(0.75)
            produto_stats['potential_revenue'] = np.maximum(
                produto_stats['receita_total'],
                receita_p75 * produto_stats['cliente_count'] / produto_stats['cliente_count'].mean()
            )
            
            # Categoriza gaps
            produto_stats['gap_category'] = pd.cut(
                produto_stats['gap_score'],
                bins=[-np.inf, 25, 75, np.inf],
                labels=['Baixo', 'Médio', 'Alto']
            )
            
            # Renomeia colunas para output
            resultado = produto_stats.rename(columns={
                'receita_total': 'current_revenue'
            }).round(2)
            
            # Ordena por gap score
            resultado = resultado.sort_values('gap_score', ascending=False)
            
            print(f"✅ Análise de gaps concluída - {len(resultado)} produtos analisados")
            return resultado
            
        except Exception as e:
            print(f"❌ Erro no cálculo de gaps: {e}")
            return pd.DataFrame({
                'produto': ['Erro no cálculo'],
                'gap_score': [0],
                'gap_category': ['Erro'],
                'current_revenue': [0],
                'potential_revenue': [0],
                'cliente_count': [0]
            })
    
    # ==========================================
    # 1. ANÁLISE DE GAPS DE OPORTUNIDADE (MÉTODO ORIGINAL)
    # ==========================================
    
    def calculate_detailed_opportunity_gaps(self, 
                                  vendas_df: pd.DataFrame,
                                  cotacoes_df: pd.DataFrame, 
                                  target_cliente: str,
                                  filters: Dict = None) -> Dict:
        """
        Calcula gaps de oportunidade comparando cliente alvo vs base
        
        Args:
            vendas_df: DataFrame de vendas
            cotacoes_df: DataFrame de cotações
            target_cliente: Código do cliente para análise
            filters: Filtros para segmentação da base comparável
            
        Returns:
            Dict com análise de gaps e oportunidades
        """
        print(f"🎯 Calculando gaps de oportunidade para cliente {target_cliente}")
        
        # Aplica filtros na base comparável
        base_vendas = self._apply_filters(vendas_df, filters) if filters else vendas_df
        base_cotacoes = self._apply_filters(cotacoes_df, filters, is_cotacoes=True) if filters else cotacoes_df
        
        # Filtra dados do cliente alvo
        cliente_vendas = base_vendas[base_vendas['cod_cliente'] == target_cliente]
        cliente_cotacoes = base_cotacoes[base_cotacoes['cod_cliente'] == target_cliente]
        
        if cliente_vendas.empty:
            return {"error": "Cliente não encontrado na base de dados"}
        
        # Calcula penetração W% (compra) na base
        base_penetracao = self._calculate_base_penetration(base_vendas, 'vlr_rol')
        
        # Calcula presença Q% (cotação) na base  
        base_cotacao_penetracao = self._calculate_base_penetration(base_cotacoes, 'preco_liq_total', material_col='material')
        
        # Calcula mix do cliente
        cliente_mix_compra = self._calculate_client_mix(cliente_vendas, 'vlr_rol')
        cliente_mix_cotacao = self._calculate_client_mix(cliente_cotacoes, 'preco_liq_total', material_col='material')
        
        # Identifica gaps de oportunidade
        gaps_oportunidade = self._identify_opportunity_gaps(
            base_penetracao, base_cotacao_penetracao,
            cliente_mix_compra, cliente_mix_cotacao
        )
        
        # Calcula estatísticas de confiança
        confidence_stats = self._calculate_confidence_intervals(base_vendas, base_cotacoes)
        
        return {
            'cliente_codigo': target_cliente,
            'cliente_nome': cliente_vendas['cliente'].iloc[0] if 'cliente' in cliente_vendas.columns else 'N/A',
            'periodo_analise': self._get_period_description(filters),
            'base_comparavel': {
                'total_clientes': base_vendas['cod_cliente'].nunique(),
                'total_materiais': base_vendas['material'].nunique(),
                'faturamento_total': float(base_vendas['vlr_rol'].sum() if 'vlr_rol' in base_vendas.columns else 0)
            },
            'cliente_performance': {
                'materiais_comprados': len(cliente_mix_compra),
                'materiais_cotados': len(cliente_mix_cotacao),
                'faturamento_total': float(cliente_vendas['vlr_rol'].sum() if 'vlr_rol' in cliente_vendas.columns else 0)
            },
            'gaps_oportunidade': gaps_oportunidade,
            'confidence_stats': confidence_stats,
            'recomendacoes': self._generate_gap_recommendations(gaps_oportunidade)
        }
    
    def _calculate_base_penetration(self, df: pd.DataFrame, valor_col: str, material_col: str = 'material') -> Dict:
        """Calcula penetração W% de cada material na base"""
        if df.empty or material_col not in df.columns:
            return {}
            
        total_clientes = df['cod_cliente'].nunique()
        
        # Clientes que compraram cada material
        material_penetracao = df.groupby(material_col).agg({
            'cod_cliente': 'nunique',
            valor_col: 'sum'
        }).reset_index()
        
        material_penetracao['w_penetracao'] = (material_penetracao['cod_cliente'] / total_clientes) * 100
        
        # Adiciona intervalos de confiança binomial
        material_penetracao['ic_inferior'], material_penetracao['ic_superior'] = zip(
            *material_penetracao.apply(
                lambda row: self._binomial_confidence_interval(
                    row['cod_cliente'], total_clientes
                ), axis=1
            )
        )
        
        return material_penetracao.set_index(material_col).to_dict('index')
    
    def _calculate_client_mix(self, df: pd.DataFrame, valor_col: str, material_col: str = 'material') -> Dict:
        """Calcula mix de materiais do cliente"""
        if df.empty or material_col not in df.columns:
            return {}
            
        client_mix = df.groupby(material_col)[valor_col].sum().to_dict()
        return client_mix
    
    def _identify_opportunity_gaps(self, base_penetracao: Dict, base_cotacao: Dict, 
                                  cliente_compra: Dict, cliente_cotacao: Dict) -> List[Dict]:
        """Identifica gaps de oportunidade com scoring estatístico"""
        gaps = []
        
        # Analisa materiais com alta penetração na base mas baixa no cliente
        for material, stats in base_penetracao.items():
            w_base = stats['w_penetracao']
            valor_base = stats.get('vlr_rol', 0)
            ic_inf = stats.get('ic_inferior', 0)
            ic_sup = stats.get('ic_superior', 0)
            
            # Status no cliente
            comprou = material in cliente_compra
            cotou = material in cliente_cotacao
            
            # Calcula score de oportunidade
            opportunity_score = self._calculate_opportunity_score(
                w_base, comprou, cotou, valor_base, ic_inf, ic_sup
            )
            
            # Presença em cotações na base
            q_base = base_cotacao.get(material, {}).get('w_penetracao', 0)
            
            if opportunity_score > 50:  # Threshold de oportunidade
                gaps.append({
                    'material': material,
                    'w_penetracao_base': round(w_base, 1),
                    'q_cotacao_base': round(q_base, 1),
                    'cliente_compra': comprou,
                    'cliente_cotacao': cotou,
                    'opportunity_score': round(opportunity_score, 1),
                    'ic_penetracao': [round(ic_inf, 1), round(ic_sup, 1)],
                    'valor_potencial': float(valor_base),
                    'explicacao': self._generate_gap_explanation(w_base, q_base, comprou, cotou),
                    'prioridade': self._classify_priority(opportunity_score)
                })
        
        # Ordena por score de oportunidade
        gaps.sort(key=lambda x: x['opportunity_score'], reverse=True)
        
        return gaps[:20]  # Top 20 oportunidades
    
    def _calculate_opportunity_score(self, w_base: float, comprou: bool, cotou: bool, 
                                   valor_base: float, ic_inf: float, ic_sup: float) -> float:
        """Calcula score de oportunidade baseado em múltiplos fatores"""
        score = 0
        
        # Peso da penetração na base (0-40 pontos)
        score += min(w_base, 40)
        
        # Penalização se já compra (reduz significativamente)
        if comprou:
            score *= 0.2
        
        # Bonus se cotou mas não comprou (indica interesse)
        if cotou and not comprou:
            score += 25
        
        # Bonus por confiabilidade estatística (IC estreito)
        ic_width = ic_sup - ic_inf
        if ic_width < 10:  # IC estreito = maior confiança
            score += 10
        
        # Bonus por valor potencial (normalizado)
        if valor_base > 0:
            valor_score = min(np.log10(valor_base + 1) * 3, 15)
            score += valor_score
        
        return min(score, 100)  # Cap em 100
    
    def _generate_gap_explanation(self, w_base: float, q_base: float, 
                                 comprou: bool, cotou: bool) -> str:
        """Gera explicação textual do gap"""
        if comprou:
            return f"Cliente já compra este item (penetração base: {w_base:.1f}%)"
        elif cotou:
            return f"Cliente cotou mas não comprou (penetração base: {w_base:.1f}%, cotações: {q_base:.1f}%)"
        else:
            return f"Presente em {w_base:.1f}% dos clientes da base e {q_base:.1f}% das cotações, mas cliente não demonstrou interesse"
    
    def _classify_priority(self, score: float) -> str:
        """Classifica prioridade baseada no score"""
        if score >= 80:
            return "🔴 ALTA"
        elif score >= 60:
            return "🟡 MÉDIA"
        else:
            return "🟢 BAIXA"
    
    # ==========================================
    # 2. ALERTAS DE INATIVIDADE
    # ==========================================
    
    def calculate_inactivity_alerts(self, vendas_df: pd.DataFrame = None, 
                                   filters: Dict = None) -> pd.DataFrame:
        """
        Calcula alertas de inatividade baseado em 90/365 dias
        
        Args:
            vendas_df: DataFrame de vendas (usa self.vendas_df se não fornecido)
            filters: Filtros adicionais
            
        Returns:
            DataFrame com alertas categorizados e estatísticas
        """
        # Usa DataFrame armazenado se não fornecido
        vendas_data = vendas_df if vendas_df is not None else self.vendas_df
        
        if vendas_data is None or vendas_data.empty:
            return pd.DataFrame({
                'cliente': ['Nenhum cliente'],
                'cod_cliente': [''],
                'category': ['Sem dados'],
                'days_since_last_purchase': [0],
                'last_purchase_date': [''],
                'total_revenue': [0]
            })
        
        print("⚠️ Calculando alertas de inatividade...")
        
        try:
            # Aplica filtros se fornecidos
            vendas_filtered = self._apply_filters(vendas_data, filters) if filters else vendas_data
            
            # Verifica se a coluna de data existe
            date_column = None
            for col in ['data_faturamento', 'data', 'data_venda']:
                if col in vendas_filtered.columns:
                    date_column = col
                    break
            
            if date_column is None:
                print("⚠️ Coluna de data não encontrada, usando data atual")
                # Cria dados sintéticos para demonstração
                unique_clients = vendas_filtered['cod_cliente'].unique()[:10]
                return pd.DataFrame({
                    'cliente': [f'Cliente {i}' for i in unique_clients],
                    'cod_cliente': unique_clients,
                    'category': ['Ativo'] * len(unique_clients),
                    'days_since_last_purchase': [30] * len(unique_clients),
                    'last_purchase_date': [self.current_date.strftime('%Y-%m-%d')] * len(unique_clients),
                    'total_revenue': [10000] * len(unique_clients)
                })
            
            # Converte coluna de data
            vendas_filtered[date_column] = pd.to_datetime(vendas_filtered[date_column], errors='coerce')
            
            # Calcula última compra por cliente
            ultima_compra = vendas_filtered.groupby('cod_cliente').agg({
                date_column: 'max',
                'cliente': 'first',
                'valor_liquido': 'sum'
            }).reset_index()
            
            ultima_compra.columns = ['cod_cliente', 'last_purchase_date', 'cliente', 'total_revenue']
            
            # Calcula dias desde última compra
            ultima_compra['days_since_last_purchase'] = (
                self.current_date - ultima_compra['last_purchase_date']
            ).dt.days
            
            # Categoriza clientes
            def categorize_inactivity(days):
                if days <= 90:
                    return 'Ativo'
                elif days <= 365:
                    return 'Atenção'
                else:
                    return 'Crítico'
            
            ultima_compra['category'] = ultima_compra['days_since_last_purchase'].apply(categorize_inactivity)
            
            # Formata data para string
            ultima_compra['last_purchase_date'] = ultima_compra['last_purchase_date'].dt.strftime('%Y-%m-%d')
            
            # Ordena por dias sem compra (decrescente)
            resultado = ultima_compra.sort_values('days_since_last_purchase', ascending=False)
            
            print(f"✅ Análise de inatividade concluída - {len(resultado)} clientes analisados")
            return resultado
            
        except Exception as e:
            print(f"❌ Erro no cálculo de inatividade: {e}")
            return pd.DataFrame({
                'cliente': ['Erro no cálculo'],
                'cod_cliente': [''],
                'category': ['Erro'],
                'days_since_last_purchase': [0],
                'last_purchase_date': [''],
                'total_revenue': [0]
            })
            'vlr_carteira': 'sum',  # Carteira atual
            'vlr_rol': 'sum',  # Faturamento total
            'material': 'nunique'  # Diversidade de produtos
        }).reset_index()
        
        # Calcula dias desde última compra
        ultima_compra['dias_sem_compra'] = (
            self.current_date - ultima_compra['data_faturamento']
        ).dt.days
        
        # Suprime alertas se há carteira ativa nos últimos 30 dias
        carteira_30d = vendas_filtered[
            vendas_filtered['data_faturamento'] >= (self.current_date - timedelta(days=30))
        ].groupby('cod_cliente')['vlr_carteira'].sum()
        
        ultima_compra['carteira_30d'] = ultima_compra['cod_cliente'].map(
            carteira_30d.fillna(0)
        ).fillna(0)
        
        # Classifica alertas
        alertas = []
        for _, cliente in ultima_compra.iterrows():
            dias = cliente['dias_sem_compra']
            carteira = cliente['carteira_30d']
            
            # Suprime alerta se há carteira ativa
            if carteira > 0:
                continue
                
            if dias >= 365:
                categoria = "🔴 CRÍTICO (>365 dias)"
                urgencia = "alta"
            elif dias >= 330:
                categoria = "🟠 ATENÇÃO (próximo 365 dias)"
                urgencia = "media"
            elif dias >= 90:
                categoria = "🟡 MONITORAR (>90 dias)"
                urgencia = "baixa"
            else:
                continue  # Não é alerta
            
            alertas.append({
                'cod_cliente': cliente['cod_cliente'],
                'cliente': cliente['cliente'],
                'dias_sem_compra': int(dias),
                'ultima_compra': cliente['data_faturamento'].strftime('%d/%m/%Y'),
                'categoria': categoria,
                'urgencia': urgencia,
                'faturamento_historico': float(cliente['vlr_rol']),
                'diversidade_produtos': int(cliente['material']),
                'recomendacao': self._generate_inactivity_recommendation(dias, cliente['vlr_rol'])
            })
        
        # Estatísticas dos alertas
        stats = self._calculate_inactivity_stats(alertas, ultima_compra)
        
        # Ordena por urgência e dias
        urgencia_order = {'alta': 3, 'media': 2, 'baixa': 1}
        alertas.sort(key=lambda x: (urgencia_order[x['urgencia']], x['dias_sem_compra']), reverse=True)
        
        return {
            'alertas': alertas,
            'estatisticas': stats,
            'resumo': self._generate_inactivity_summary(alertas),
            'data_calculo': self.current_date.strftime('%d/%m/%Y %H:%M')
        }
    
    def _generate_inactivity_recommendation(self, dias: int, faturamento: float) -> str:
        """Gera recomendação baseada no perfil de inatividade"""
        if dias >= 365:
            if faturamento > 50000:
                return "Cliente estratégico inativo - contato urgente da gerência"
            else:
                return "Verificar viabilidade de reativação"
        elif dias >= 330:
            return "Agendamento proativo para evitar inatividade total"
        else:
            return "Acompanhamento comercial de rotina"
    
    def _calculate_inactivity_stats(self, alertas: List[Dict], clientes_total: pd.DataFrame) -> Dict:
        """Calcula estatísticas dos alertas de inatividade"""
        total_clientes = len(clientes_total)
        total_alertas = len(alertas)
        
        # Distribui por categoria
        criticos = sum(1 for a in alertas if a['urgencia'] == 'alta')
        atencao = sum(1 for a in alertas if a['urgencia'] == 'media')
        monitorar = sum(1 for a in alertas if a['urgencia'] == 'baixa')
        
        # Faturamento em risco
        faturamento_risco = sum(a['faturamento_historico'] for a in alertas)
        
        # Média de dias sem compra
        dias_media = np.mean([a['dias_sem_compra'] for a in alertas]) if alertas else 0
        
        return {
            'total_clientes': total_clientes,
            'total_alertas': total_alertas,
            'percentual_alertas': round((total_alertas / total_clientes) * 100, 1) if total_clientes > 0 else 0,
            'distribuicao': {
                'criticos': criticos,
                'atencao': atencao,
                'monitorar': monitorar
            },
            'faturamento_em_risco': float(faturamento_risco),
            'dias_sem_compra_medio': round(dias_media, 1)
        }
    
    def _generate_inactivity_summary(self, alertas: List[Dict]) -> str:
        """Gera resumo executivo dos alertas"""
        if not alertas:
            return "✅ Nenhum alerta de inatividade identificado no período"
        
        criticos = sum(1 for a in alertas if a['urgencia'] == 'alta')
        total = len(alertas)
        
        if criticos > 0:
            return f"⚠️ {criticos} cliente(s) em situação crítica entre {total} alertas totais"
        else:
            return f"📊 {total} cliente(s) requerem acompanhamento preventivo"
    
    # ==========================================
    # 3. ANÁLISE DE SAZONALIDADE
    # ==========================================
    
    def analyze_seasonality(self, vendas_df: pd.DataFrame, 
                           filters: Dict = None) -> Dict:
        """
        Análise estatística de sazonalidade das vendas
        
        Returns:
            Dict com decomposição temporal e insights de sazonalidade
        """
        print("📈 Analisando sazonalidade das vendas...")
        
        # Aplica filtros se fornecidos
        vendas_filtered = self._apply_filters(vendas_df, filters) if filters else vendas_df
        
        if vendas_filtered.empty:
            return {"error": "Nenhum dado de vendas encontrado"}
        
        # Prepara série temporal mensal
        vendas_monthly = self._prepare_monthly_series(vendas_filtered)
        
        if vendas_monthly.empty:
            return {"error": "Dados insuficientes para análise de sazonalidade"}
        
        # Decomposição de série temporal
        decomposition = self._decompose_time_series(vendas_monthly)
        
        # Análise de concentração 1º vs 2º semestre
        concentration_analysis = self._analyze_semester_concentration(vendas_monthly)
        
        # Análise estatística de significância
        statistical_tests = self._perform_seasonality_tests(vendas_monthly)
        
        # Padrões mensais
        monthly_patterns = self._analyze_monthly_patterns(vendas_monthly)
        
        return {
            'periodo_analise': f"{vendas_monthly.index.min().strftime('%m/%Y')} a {vendas_monthly.index.max().strftime('%m/%Y')}",
            'decomposicao_temporal': decomposition,
            'concentracao_semestral': concentration_analysis,
            'testes_estatisticos': statistical_tests,
            'padroes_mensais': monthly_patterns,
            'insights': self._generate_seasonality_insights(concentration_analysis, statistical_tests)
        }
    
    def _prepare_monthly_series(self, vendas_df: pd.DataFrame) -> pd.DataFrame:
        """Prepara série temporal mensal"""
        if 'data_faturamento' not in vendas_df.columns:
            return pd.DataFrame()
        
        # Converte para datetime se necessário
        vendas_df['data_faturamento'] = pd.to_datetime(vendas_df['data_faturamento'])
        
        # Agrupa por mês
        monthly_data = vendas_df.groupby(
            vendas_df['data_faturamento'].dt.to_period('M')
        ).agg({
            'vlr_entrada': 'sum',
            'vlr_carteira': 'sum', 
            'vlr_rol': 'sum'
        })
        
        # Remove valores nulos
        monthly_data = monthly_data.fillna(0)
        
        return monthly_data
    
    def _decompose_time_series(self, monthly_data: pd.DataFrame) -> Dict:
        """Decomposição STL da série temporal"""
        try:
            from statsmodels.tsa.seasonal import seasonal_decompose
            
            # Usa vlr_rol como série principal
            if 'vlr_rol' not in monthly_data.columns:
                return {"error": "Coluna vlr_rol não encontrada"}
            
            ts = monthly_data['vlr_rol']
            
            # Decomposição aditiva (mínimo 24 observações)
            if len(ts) >= 24:
                decomp = seasonal_decompose(ts, model='additive', period=12)
                
                return {
                    'trend': decomp.trend.dropna().to_dict(),
                    'seasonal': decomp.seasonal.to_dict(),
                    'residual': decomp.resid.dropna().to_dict(),
                    'seasonal_strength': float(np.var(decomp.seasonal) / np.var(ts)) if np.var(ts) > 0 else 0
                }
            else:
                # Análise simplificada para séries curtas
                monthly_avg = ts.groupby(ts.index.month).mean()
                seasonal_coef = (monthly_avg - monthly_avg.mean()) / monthly_avg.mean() * 100
                
                return {
                    'seasonal_coefficients': seasonal_coef.to_dict(),
                    'seasonal_strength': float(seasonal_coef.std() / 100),
                    'observacao': "Série muito curta para decomposição completa"
                }
                
        except ImportError:
            # Fallback sem statsmodels
            monthly_avg = monthly_data['vlr_rol'].groupby(monthly_data.index.month).mean()
            return {
                'monthly_averages': monthly_avg.to_dict(),
                'observacao': "Decomposição completa requer statsmodels"
            }
    
    def _analyze_semester_concentration(self, monthly_data: pd.DataFrame) -> Dict:
        """Analisa concentração 1º vs 2º semestre"""
        yearly_data = []
        
        # Agrupa por ano
        for year in monthly_data.index.year.unique():
            year_data = monthly_data[monthly_data.index.year == year]
            
            # 1º semestre (Jan-Jul)
            primeiro_sem = year_data[year_data.index.month <= 7]['vlr_rol'].sum()
            
            # 2º semestre (Ago-Dez)
            segundo_sem = year_data[year_data.index.month > 7]['vlr_rol'].sum()
            
            total_ano = primeiro_sem + segundo_sem
            
            if total_ano > 0:
                yearly_data.append({
                    'ano': year,
                    'primeiro_semestre': float(primeiro_sem),
                    'segundo_semestre': float(segundo_sem),
                    'percentual_primeiro': float(primeiro_sem / total_ano * 100),
                    'percentual_segundo': float(segundo_sem / total_ano * 100)
                })
        
        if not yearly_data:
            return {"error": "Dados insuficientes para análise semestral"}
        
        # Médias
        avg_primeiro = np.mean([y['percentual_primeiro'] for y in yearly_data])
        avg_segundo = np.mean([y['percentual_segundo'] for y in yearly_data])
        
        # Intervalos de confiança
        if len(yearly_data) > 1:
            primeiro_values = [y['percentual_primeiro'] for y in yearly_data]
            ic_primeiro = self._confidence_interval_mean(primeiro_values)
            
            segundo_values = [y['percentual_segundo'] for y in yearly_data]
            ic_segundo = self._confidence_interval_mean(segundo_values)
        else:
            ic_primeiro = [avg_primeiro, avg_primeiro]
            ic_segundo = [avg_segundo, avg_segundo]
        
        return {
            'detalhes_anuais': yearly_data,
            'medias': {
                'primeiro_semestre': round(avg_primeiro, 1),
                'segundo_semestre': round(avg_segundo, 1)
            },
            'intervalos_confianca': {
                'primeiro_semestre': [round(ic_primeiro[0], 1), round(ic_primeiro[1], 1)],
                'segundo_semestre': [round(ic_segundo[0], 1), round(ic_segundo[1], 1)]
            }
        }
    
    def _perform_seasonality_tests(self, monthly_data: pd.DataFrame) -> Dict:
        """Realiza testes estatísticos de sazonalidade"""
        ts = monthly_data['vlr_rol']
        
        if len(ts) < 12:
            return {"error": "Dados insuficientes para testes estatísticos"}
        
        # Teste de Kruskal-Wallis por mês
        monthly_groups = [
            ts[ts.index.month == month].values 
            for month in range(1, 13) 
            if len(ts[ts.index.month == month]) > 0
        ]
        
        # Remove grupos vazios
        monthly_groups = [group for group in monthly_groups if len(group) > 0]
        
        if len(monthly_groups) >= 3:
            try:
                kw_stat, kw_pvalue = stats.kruskal(*monthly_groups)
                
                return {
                    'kruskal_wallis': {
                        'estatistica': float(kw_stat),
                        'p_value': float(kw_pvalue),
                        'significativo': kw_pvalue < 0.05,
                        'interpretacao': "Sazonalidade significativa detectada" if kw_pvalue < 0.05 else "Não há evidência de sazonalidade"
                    }
                }
            except:
                return {"observacao": "Não foi possível realizar teste estatístico"}
        else:
            return {"observacao": "Dados insuficientes para teste de sazonalidade"}
    
    def _analyze_monthly_patterns(self, monthly_data: pd.DataFrame) -> Dict:
        """Analisa padrões mensais detalhados"""
        monthly_stats = monthly_data.groupby(monthly_data.index.month).agg({
            'vlr_rol': ['mean', 'std', 'count']
        }).round(2)
        
        # Flatten column names
        monthly_stats.columns = ['media', 'desvio', 'observacoes']
        
        # Identifica picos e vales
        media_overall = monthly_stats['media'].mean()
        monthly_stats['percentual_media'] = (monthly_stats['media'] / media_overall * 100).round(1)
        
        # Classifica meses
        monthly_stats['classificacao'] = monthly_stats['percentual_media'].apply(
            lambda x: 'PICO' if x > 115 else 'VALE' if x < 85 else 'NORMAL'
        )
        
        meses_nomes = {
            1: 'Janeiro', 2: 'Fevereiro', 3: 'Março', 4: 'Abril',
            5: 'Maio', 6: 'Junho', 7: 'Julho', 8: 'Agosto',
            9: 'Setembro', 10: 'Outubro', 11: 'Novembro', 12: 'Dezembro'
        }
        
        # Adiciona nomes dos meses
        monthly_stats['mes_nome'] = monthly_stats.index.map(meses_nomes)
        
        return monthly_stats.to_dict('index')
    
    def _generate_seasonality_insights(self, concentration: Dict, tests: Dict) -> List[str]:
        """Gera insights baseados na análise de sazonalidade"""
        insights = []
        
        if 'medias' in concentration:
            primeiro = concentration['medias']['primeiro_semestre']
            segundo = concentration['medias']['segundo_semestre']
            
            if primeiro > 55:
                insights.append(f"📊 Concentração no 1º semestre: {primeiro:.1f}% das vendas ocorrem até julho")
            elif segundo > 55:
                insights.append(f"📊 Concentração no 2º semestre: {segundo:.1f}% das vendas ocorrem de agosto a dezembro")
            else:
                insights.append("📊 Distribuição equilibrada entre semestres")
        
        if 'kruskal_wallis' in tests:
            if tests['kruskal_wallis']['significativo']:
                insights.append("📈 Padrão sazonal estatisticamente significativo identificado")
            else:
                insights.append("📈 Vendas não apresentam sazonalidade estatisticamente significativa")
        
        return insights
    
    # ==========================================
    # 4. ANÁLISE DE DEMANDAS DE COTAÇÃO
    # ==========================================
    
    def analyze_quotation_demand(self, cotacoes_df: pd.DataFrame, 
                                vendas_df: pd.DataFrame,
                                filters: Dict = None) -> Dict:
        """
        Análise da demanda de cotações e esforço da equipe
        
        Returns:
            Dict com análise temporal de cotações e métricas de eficiência
        """
        print("📋 Analisando demanda de cotações...")
        
        # Aplica filtros
        cotacoes_filtered = self._apply_filters(cotacoes_df, filters, is_cotacoes=True) if filters else cotacoes_df
        vendas_filtered = self._apply_filters(vendas_df, filters) if filters else vendas_df
        
        if cotacoes_filtered.empty:
            return {"error": "Nenhum dado de cotação encontrado"}
        
        # Série temporal mensal de cotações
        monthly_quotations = self._prepare_quotation_monthly_series(cotacoes_filtered)
        
        # Métricas de esforço
        effort_metrics = self._calculate_effort_metrics(cotacoes_filtered, vendas_filtered)
        
        # Taxa de conversão
        conversion_analysis = self._analyze_conversion_rates(cotacoes_filtered, vendas_filtered)
        
        # Sazonalidade das cotações
        quotation_seasonality = self._analyze_quotation_seasonality(monthly_quotations)
        
        # Insights de performance
        performance_insights = self._generate_quotation_insights(effort_metrics, conversion_analysis)
        
        return {
            'periodo_analise': self._get_period_description(filters),
            'serie_temporal_mensal': monthly_quotations.to_dict('index') if not monthly_quotations.empty else {},
            'metricas_esforco': effort_metrics,
            'analise_conversao': conversion_analysis,
            'sazonalidade_cotacoes': quotation_seasonality,
            'insights_performance': performance_insights
        }
    
    def _prepare_quotation_monthly_series(self, cotacoes_df: pd.DataFrame) -> pd.DataFrame:
        """Prepara série temporal mensal de cotações"""
        if 'data' not in cotacoes_df.columns:
            return pd.DataFrame()
        
        # Converte para datetime
        cotacoes_df['data'] = pd.to_datetime(cotacoes_df['data'])
        
        # Agrupa por mês
        monthly_quotes = cotacoes_df.groupby(
            cotacoes_df['data'].dt.to_period('M')
        ).agg({
            'numero_cotacao': 'nunique',  # Número de cotações únicas
            'preco_liq_total': 'sum',     # Valor total cotado
            'cod_cliente': 'nunique'      # Clientes únicos que cotaram
        }).fillna(0)
        
        # Renomeia colunas
        monthly_quotes.columns = ['qtd_cotacoes', 'valor_cotado', 'clientes_unicos']
        
        return monthly_quotes
    
    def _calculate_effort_metrics(self, cotacoes_df: pd.DataFrame, vendas_df: pd.DataFrame) -> Dict:
        """Calcula métricas de esforço da equipe"""
        # Total de cotações e clientes ativos
        total_cotacoes = cotacoes_df['numero_cotacao'].nunique() if 'numero_cotacao' in cotacoes_df.columns else 0
        clientes_cotaram = cotacoes_df['cod_cliente'].nunique() if not cotacoes_df.empty else 0
        clientes_compraram = vendas_df['cod_cliente'].nunique() if not vendas_df.empty else 0
        
        # Índice de esforço relativo
        indice_esforco = (total_cotacoes / max(clientes_cotaram, 1)) if clientes_cotaram > 0 else 0
        
        # Valor médio por cotação
        if not cotacoes_df.empty and 'preco_liq_total' in cotacoes_df.columns:
            valor_medio_cotacao = cotacoes_df['preco_liq_total'].mean()
        else:
            valor_medio_cotacao = 0
        
        # Distribuição de cotações por cliente
        if not cotacoes_df.empty and 'cod_cliente' in cotacoes_df.columns:
            cotacoes_por_cliente = cotacoes_df.groupby('cod_cliente')['numero_cotacao'].nunique()
            
            quartis = np.percentile(cotacoes_por_cliente.values, [25, 50, 75])
        else:
            quartis = [0, 0, 0]
        
        return {
            'total_cotacoes': int(total_cotacoes),
            'clientes_cotaram': int(clientes_cotaram),
            'clientes_compraram': int(clientes_compraram),
            'indice_esforco_relativo': round(indice_esforco, 2),
            'valor_medio_cotacao': float(valor_medio_cotacao),
            'distribuicao_por_cliente': {
                'q1': float(quartis[0]),
                'mediana': float(quartis[1]),
                'q3': float(quartis[2])
            }
        }
    
    def _analyze_conversion_rates(self, cotacoes_df: pd.DataFrame, vendas_df: pd.DataFrame) -> Dict:
        """Analisa taxas de conversão cotação → pedido"""
        if cotacoes_df.empty or vendas_df.empty:
            return {"error": "Dados insuficientes para análise de conversão"}
        
        # Clientes que cotaram
        clientes_cotaram = set(cotacoes_df['cod_cliente'].unique())
        
        # Clientes que compraram
        clientes_compraram = set(vendas_df['cod_cliente'].unique())
        
        # Conversão de clientes
        clientes_converteram = clientes_cotaram & clientes_compraram
        taxa_conversao_clientes = (len(clientes_converteram) / len(clientes_cotaram)) * 100 if clientes_cotaram else 0
        
        # Conversão por material (mais complexo - aproximação)
        materiais_cotados = set(cotacoes_df['material'].unique()) if 'material' in cotacoes_df.columns else set()
        materiais_comprados = set(vendas_df['material'].unique()) if 'material' in vendas_df.columns else set()
        materiais_converteram = materiais_cotados & materiais_comprados
        
        taxa_conversao_materiais = (len(materiais_converteram) / len(materiais_cotados)) * 100 if materiais_cotados else 0
        
        # Valor de conversão
        valor_cotado_total = cotacoes_df['preco_liq_total'].sum() if 'preco_liq_total' in cotacoes_df.columns else 0
        valor_vendido_total = vendas_df['vlr_rol'].sum() if 'vlr_rol' in vendas_df.columns else 0
        
        return {
            'taxa_conversao_clientes': round(taxa_conversao_clientes, 1),
            'taxa_conversao_materiais': round(taxa_conversao_materiais, 1),
            'clientes_cotaram': len(clientes_cotaram),
            'clientes_converteram': len(clientes_converteram),
            'materiais_cotados': len(materiais_cotados),
            'materiais_converteram': len(materiais_converteram),
            'valor_cotado': float(valor_cotado_total),
            'valor_convertido': float(valor_vendido_total),
            'eficiencia_valor': round((valor_vendido_total / valor_cotado_total) * 100, 1) if valor_cotado_total > 0 else 0
        }
    
    def _analyze_quotation_seasonality(self, monthly_quotes: pd.DataFrame) -> Dict:
        """Analisa sazonalidade das cotações"""
        if monthly_quotes.empty:
            return {"error": "Dados insuficientes"}
        
        # Padrão mensal
        monthly_avg = monthly_quotes.groupby(monthly_quotes.index.month).mean()
        
        # Identifica meses de pico e vale
        overall_avg = monthly_avg['qtd_cotacoes'].mean()
        
        picos = monthly_avg[monthly_avg['qtd_cotacoes'] > overall_avg * 1.2].index.tolist()
        vales = monthly_avg[monthly_avg['qtd_cotacoes'] < overall_avg * 0.8].index.tolist()
        
        meses_nomes = {
            1: 'Janeiro', 2: 'Fevereiro', 3: 'Março', 4: 'Abril',
            5: 'Maio', 6: 'Junho', 7: 'Julho', 8: 'Agosto',
            9: 'Setembro', 10: 'Outubro', 11: 'Novembro', 12: 'Dezembro'
        }
        
        return {
            'media_mensal': monthly_avg.to_dict('index'),
            'meses_pico': [meses_nomes[m] for m in picos],
            'meses_vale': [meses_nomes[m] for m in vales],
            'coeficiente_variacao': float(monthly_avg['qtd_cotacoes'].std() / monthly_avg['qtd_cotacoes'].mean()) if monthly_avg['qtd_cotacoes'].mean() > 0 else 0
        }
    
    def _generate_quotation_insights(self, effort_metrics: Dict, conversion_analysis: Dict) -> List[str]:
        """Gera insights de performance das cotações"""
        insights = []
        
        # Insights de esforço
        if effort_metrics['indice_esforco_relativo'] > 3:
            insights.append(f"⚠️ Alto esforço: {effort_metrics['indice_esforco_relativo']:.1f} cotações por cliente")
        elif effort_metrics['indice_esforco_relativo'] < 1.5:
            insights.append(f"✅ Esforço otimizado: {effort_metrics['indice_esforco_relativo']:.1f} cotações por cliente")
        
        # Insights de conversão
        if 'taxa_conversao_clientes' in conversion_analysis:
            taxa = conversion_analysis['taxa_conversao_clientes']
            if taxa > 70:
                insights.append(f"🎯 Excelente conversão de clientes: {taxa:.1f}%")
            elif taxa < 40:
                insights.append(f"📈 Oportunidade de melhoria na conversão: {taxa:.1f}%")
        
        return insights
    
    # ==========================================
    # MÉTODOS AUXILIARES
    # ==========================================
    
    def _apply_filters(self, df: pd.DataFrame, filters: Dict, is_cotacoes: bool = False) -> pd.DataFrame:
        """Aplica filtros aos dados"""
        if df.empty or not filters:
            return df
            
        df_filtered = df.copy()
        
        # Filtro de ano
        if filters.get('ano'):
            date_col = 'data' if is_cotacoes else 'data_faturamento'
            if date_col in df_filtered.columns:
                df_filtered[date_col] = pd.to_datetime(df_filtered[date_col])
                if isinstance(filters['ano'], list) and len(filters['ano']) == 2:
                    start_year, end_year = filters['ano']
                    df_filtered = df_filtered[
                        (df_filtered[date_col].dt.year >= start_year) &
                        (df_filtered[date_col].dt.year <= end_year)
                    ]
        
        # Filtro de canal (apenas para vendas)
        if not is_cotacoes and filters.get('canal') and 'canal_distribuicao' in df_filtered.columns:
            if isinstance(filters['canal'], list):
                df_filtered = df_filtered[df_filtered['canal_distribuicao'].isin(filters['canal'])]
        
        # Filtro de cliente
        if filters.get('cliente') and 'cod_cliente' in df_filtered.columns:
            if isinstance(filters['cliente'], list):
                df_filtered = df_filtered[df_filtered['cod_cliente'].isin(filters['cliente'])]
        
        return df_filtered
    
    def _binomial_confidence_interval(self, successes: int, trials: int, confidence: float = 0.95) -> Tuple[float, float]:
        """Calcula intervalo de confiança binomial"""
        if trials == 0:
            return (0.0, 0.0)
        
        # Método Wilson
        z = stats.norm.ppf((1 + confidence) / 2)
        p = successes / trials
        
        denominator = 1 + z**2 / trials
        center = (p + z**2 / (2 * trials)) / denominator
        margin = z * np.sqrt((p * (1 - p) + z**2 / (4 * trials)) / trials) / denominator
        
        lower = max(0, (center - margin) * 100)
        upper = min(100, (center + margin) * 100)
        
        return (lower, upper)
    
    def _confidence_interval_mean(self, values: List[float], confidence: float = 0.95) -> Tuple[float, float]:
        """Calcula intervalo de confiança para média"""
        if len(values) < 2:
            return (values[0] if values else 0, values[0] if values else 0)
        
        mean = np.mean(values)
        sem = stats.sem(values)  # Standard error of mean
        
        # t-distribution para amostras pequenas
        degrees_freedom = len(values) - 1
        t_value = stats.t.ppf((1 + confidence) / 2, degrees_freedom)
        
        margin = t_value * sem
        
        return (mean - margin, mean + margin)
    
    def _get_period_description(self, filters: Dict) -> str:
        """Gera descrição textual do período analisado"""
        if not filters:
            return "Período completo disponível"
        
        parts = []
        
        if filters.get('ano'):
            if isinstance(filters['ano'], list) and len(filters['ano']) == 2:
                parts.append(f"Anos: {filters['ano'][0]}-{filters['ano'][1]}")
            else:
                parts.append(f"Ano: {filters['ano']}")
        
        if filters.get('mes'):
            if isinstance(filters['mes'], list) and len(filters['mes']) == 2:
                parts.append(f"Meses: {filters['mes'][0]}-{filters['mes'][1]}")
        
        return " | ".join(parts) if parts else "Período filtrado"
    
    def _generate_gap_recommendations(self, gaps: List[Dict]) -> List[str]:
        """Gera recomendações baseadas nos gaps identificados"""
        if not gaps:
            return ["✅ Cliente possui mix alinhado com a base comparável"]
        
        recommendations = []
        
        # Top 3 oportunidades
        top_gaps = gaps[:3]
        
        for gap in top_gaps:
            material = gap['material']
            score = gap['opportunity_score']
            w_base = gap['w_penetracao_base']
            
            if gap['cliente_cotacao']:
                rec = f"🎯 {material}: Cliente cotou mas não comprou (oportunidade {score:.0f}pts)"
            else:
                rec = f"🔍 {material}: Presente em {w_base:.0f}% da base, mas cliente não demonstrou interesse"
            
            recommendations.append(rec)
        
        # Recomendação geral
        if len(gaps) > 3:
            recommendations.append(f"📊 Total de {len(gaps)} oportunidades identificadas")
        
        return recommendations
