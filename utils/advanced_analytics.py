"""
M√≥dulo de Analytics Avan√ßados para Dashboard WEG
Implementa an√°lises estat√≠sticas, gaps de oportunidade, alertas e insights inteligentes
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union
from scipy import stats
import warnings
from utils.db import SENTINEL_ALL

warnings.filterwarnings('ignore')

class AdvancedAnalytics:
    """Classe para Analytics Avan√ßados com fundamenta√ß√£o estat√≠stica"""
    
    def __init__(self, vendas_df: pd.DataFrame = None, cotacoes_df: pd.DataFrame = None):
        """
        Inicializa o analisador com dados opcionais
        
        Args:
            vendas_df: DataFrame de vendas (opcional)
            cotacoes_df: DataFrame de cota√ß√µes (opcional)
        """
        self.current_date = datetime.now()
        self.confidence_level = 0.95  # N√≠vel de confian√ßa padr√£o 95%
        self.vendas_df = vendas_df
        self.cotacoes_df = cotacoes_df
        
    # ==========================================
    # M√âTODOS SIMPLIFICADOS PARA DASHBOARD
    # ==========================================
    
    def calculate_opportunity_gaps(self, vendas_df: pd.DataFrame = None, cotacoes_df: pd.DataFrame = None) -> pd.DataFrame:
        """
        Vers√£o simplificada para an√°lise de gaps de oportunidade
        Analisa todos os produtos e identifica oportunidades baseado em padr√µes de compra
        
        Args:
            vendas_df: DataFrame de vendas (usa self.vendas_df se n√£o fornecido)
            cotacoes_df: DataFrame de cota√ß√µes (usa self.cotacoes_df se n√£o fornecido)
            
        Returns:
            DataFrame com an√°lise de gaps por produto
        """
        # Usa DataFrames armazenados se n√£o fornecidos
        vendas_data = vendas_df if vendas_df is not None else self.vendas_df
        cotacoes_data = cotacoes_df if cotacoes_df is not None else self.cotacoes_df
        
        if vendas_data is None or vendas_data.empty:
            return pd.DataFrame({
                'produto': ['Nenhum produto'],
                'gap_score': [0],
                'gap_category': ['Sem dados'],
                'current_revenue': [0],
                'potential_revenue': [0],
                'cliente_count': [0]
            })
        
        print("üéØ Calculando gaps de oportunidade para todos os produtos")
        
        try:
            # Agrupa vendas por produto
            produto_stats = vendas_data.groupby('produto').agg({
                'valor_liquido': ['sum', 'mean', 'count'],
                'cod_cliente': 'nunique'
            }).round(2)
            
            produto_stats.columns = ['receita_total', 'receita_media', 'vendas_count', 'cliente_count']
            produto_stats = produto_stats.reset_index()
            
            # Calcula estat√≠sticas gerais
            receita_mean = produto_stats['receita_total'].mean()
            receita_std = produto_stats['receita_total'].std()
            
            # Calcula gap score baseado em desvio padr√£o da receita
            produto_stats['gap_score'] = np.where(
                produto_stats['receita_total'] > 0,
                ((produto_stats['receita_total'] - receita_mean) / receita_std * 25 + 50).clip(0, 100),
                0
            )
            
            # Calcula receita potencial (estimativa baseada no percentil 75)
            receita_p75 = produto_stats['receita_total'].quantile(0.75)
            produto_stats['potential_revenue'] = np.maximum(
                produto_stats['receita_total'],
                receita_p75 * produto_stats['cliente_count'] / produto_stats['cliente_count'].mean()
            )
            
            # Categoriza gaps
            produto_stats['gap_category'] = pd.cut(
                produto_stats['gap_score'],
                bins=[-np.inf, 25, 75, np.inf],
                labels=['Baixo', 'M√©dio', 'Alto']
            )
            
            # Renomeia colunas para output
            resultado = produto_stats.rename(columns={
                'receita_total': 'current_revenue'
            }).round(2)
            
            # Ordena por gap score
            resultado = resultado.sort_values('gap_score', ascending=False)
            
            print(f"‚úÖ An√°lise de gaps conclu√≠da - {len(resultado)} produtos analisados")
            return resultado
            
        except Exception as e:
            print(f"‚ùå Erro no c√°lculo de gaps: {e}")
            return pd.DataFrame({
                'produto': ['Erro no c√°lculo'],
                'gap_score': [0],
                'gap_category': ['Erro'],
                'current_revenue': [0],
                'potential_revenue': [0],
                'cliente_count': [0]
            })
    
    # ==========================================
    # 1. AN√ÅLISE DE GAPS DE OPORTUNIDADE (M√âTODO ORIGINAL)
    # ==========================================
    
    def calculate_detailed_opportunity_gaps(self, 
                                  vendas_df: pd.DataFrame,
                                  cotacoes_df: pd.DataFrame, 
                                  target_cliente: str,
                                  filters: Dict = None) -> Dict:
        """
        Calcula gaps de oportunidade comparando cliente alvo vs base
        
        Args:
            vendas_df: DataFrame de vendas
            cotacoes_df: DataFrame de cota√ß√µes
            target_cliente: C√≥digo do cliente para an√°lise
            filters: Filtros para segmenta√ß√£o da base compar√°vel
            
        Returns:
            Dict com an√°lise de gaps e oportunidades
        """
        print(f"üéØ Calculando gaps de oportunidade para cliente {target_cliente}")
        
        # Aplica filtros na base compar√°vel
        base_vendas = self._apply_filters(vendas_df, filters) if filters else vendas_df
        base_cotacoes = self._apply_filters(cotacoes_df, filters, is_cotacoes=True) if filters else cotacoes_df
        
        # Filtra dados do cliente alvo
        cliente_vendas = base_vendas[base_vendas['cod_cliente'] == target_cliente]
        cliente_cotacoes = base_cotacoes[base_cotacoes['cod_cliente'] == target_cliente]
        
        if cliente_vendas.empty:
            return {"error": "Cliente n√£o encontrado na base de dados"}
        
        # Calcula penetra√ß√£o W% (compra) na base
        base_penetracao = self._calculate_base_penetration(base_vendas, 'vlr_rol')
        
        # Calcula presen√ßa Q% (cota√ß√£o) na base  
        base_cotacao_penetracao = self._calculate_base_penetration(base_cotacoes, 'preco_liq_total', material_col='material')
        
        # Calcula mix do cliente
        cliente_mix_compra = self._calculate_client_mix(cliente_vendas, 'vlr_rol')
        cliente_mix_cotacao = self._calculate_client_mix(cliente_cotacoes, 'preco_liq_total', material_col='material')
        
        # Identifica gaps de oportunidade
        gaps_oportunidade = self._identify_opportunity_gaps(
            base_penetracao, base_cotacao_penetracao,
            cliente_mix_compra, cliente_mix_cotacao
        )
        
        # Calcula estat√≠sticas de confian√ßa
        confidence_stats = self._calculate_confidence_intervals(base_vendas, base_cotacoes)
        
        return {
            'cliente_codigo': target_cliente,
            'cliente_nome': cliente_vendas['cliente'].iloc[0] if 'cliente' in cliente_vendas.columns else 'N/A',
            'periodo_analise': self._get_period_description(filters),
            'base_comparavel': {
                'total_clientes': base_vendas['cod_cliente'].nunique(),
                'total_materiais': base_vendas['material'].nunique(),
                'faturamento_total': float(base_vendas['vlr_rol'].sum() if 'vlr_rol' in base_vendas.columns else 0)
            },
            'cliente_performance': {
                'materiais_comprados': len(cliente_mix_compra),
                'materiais_cotados': len(cliente_mix_cotacao),
                'faturamento_total': float(cliente_vendas['vlr_rol'].sum() if 'vlr_rol' in cliente_vendas.columns else 0)
            },
            'gaps_oportunidade': gaps_oportunidade,
            'confidence_stats': confidence_stats,
            'recomendacoes': self._generate_gap_recommendations(gaps_oportunidade)
        }
    
    def _calculate_base_penetration(self, df: pd.DataFrame, valor_col: str, material_col: str = 'material') -> Dict:
        """Calcula penetra√ß√£o W% de cada material na base"""
        if df.empty or material_col not in df.columns:
            return {}
            
        total_clientes = df['cod_cliente'].nunique()
        
        # Clientes que compraram cada material
        material_penetracao = df.groupby(material_col).agg({
            'cod_cliente': 'nunique',
            valor_col: 'sum'
        }).reset_index()
        
        material_penetracao['w_penetracao'] = (material_penetracao['cod_cliente'] / total_clientes) * 100
        
        # Adiciona intervalos de confian√ßa binomial
        material_penetracao['ic_inferior'], material_penetracao['ic_superior'] = zip(
            *material_penetracao.apply(
                lambda row: self._binomial_confidence_interval(
                    row['cod_cliente'], total_clientes
                ), axis=1
            )
        )
        
        return material_penetracao.set_index(material_col).to_dict('index')
    
    def _calculate_client_mix(self, df: pd.DataFrame, valor_col: str, material_col: str = 'material') -> Dict:
        """Calcula mix de materiais do cliente"""
        if df.empty or material_col not in df.columns:
            return {}
            
        client_mix = df.groupby(material_col)[valor_col].sum().to_dict()
        return client_mix
    
    def _identify_opportunity_gaps(self, base_penetracao: Dict, base_cotacao: Dict, 
                                  cliente_compra: Dict, cliente_cotacao: Dict) -> List[Dict]:
        """Identifica gaps de oportunidade com scoring estat√≠stico"""
        gaps = []
        
        # Analisa materiais com alta penetra√ß√£o na base mas baixa no cliente
        for material, stats in base_penetracao.items():
            w_base = stats['w_penetracao']
            valor_base = stats.get('vlr_rol', 0)
            ic_inf = stats.get('ic_inferior', 0)
            ic_sup = stats.get('ic_superior', 0)
            
            # Status no cliente
            comprou = material in cliente_compra
            cotou = material in cliente_cotacao
            
            # Calcula score de oportunidade
            opportunity_score = self._calculate_opportunity_score(
                w_base, comprou, cotou, valor_base, ic_inf, ic_sup
            )
            
            # Presen√ßa em cota√ß√µes na base
            q_base = base_cotacao.get(material, {}).get('w_penetracao', 0)
            
            if opportunity_score > 50:  # Threshold de oportunidade
                gaps.append({
                    'material': material,
                    'w_penetracao_base': round(w_base, 1),
                    'q_cotacao_base': round(q_base, 1),
                    'cliente_compra': comprou,
                    'cliente_cotacao': cotou,
                    'opportunity_score': round(opportunity_score, 1),
                    'ic_penetracao': [round(ic_inf, 1), round(ic_sup, 1)],
                    'valor_potencial': float(valor_base),
                    'explicacao': self._generate_gap_explanation(w_base, q_base, comprou, cotou),
                    'prioridade': self._classify_priority(opportunity_score)
                })
        
        # Ordena por score de oportunidade
        gaps.sort(key=lambda x: x['opportunity_score'], reverse=True)
        
        return gaps[:20]  # Top 20 oportunidades
    
    def _calculate_opportunity_score(self, w_base: float, comprou: bool, cotou: bool, 
                                   valor_base: float, ic_inf: float, ic_sup: float) -> float:
        """Calcula score de oportunidade baseado em m√∫ltiplos fatores"""
        score = 0
        
        # Peso da penetra√ß√£o na base (0-40 pontos)
        score += min(w_base, 40)
        
        # Penaliza√ß√£o se j√° compra (reduz significativamente)
        if comprou:
            score *= 0.2
        
        # Bonus se cotou mas n√£o comprou (indica interesse)
        if cotou and not comprou:
            score += 25
        
        # Bonus por confiabilidade estat√≠stica (IC estreito)
        ic_width = ic_sup - ic_inf
        if ic_width < 10:  # IC estreito = maior confian√ßa
            score += 10
        
        # Bonus por valor potencial (normalizado)
        if valor_base > 0:
            valor_score = min(np.log10(valor_base + 1) * 3, 15)
            score += valor_score
        
        return min(score, 100)  # Cap em 100
    
    def _generate_gap_explanation(self, w_base: float, q_base: float, 
                                 comprou: bool, cotou: bool) -> str:
        """Gera explica√ß√£o textual do gap"""
        if comprou:
            return f"Cliente j√° compra este item (penetra√ß√£o base: {w_base:.1f}%)"
        elif cotou:
            return f"Cliente cotou mas n√£o comprou (penetra√ß√£o base: {w_base:.1f}%, cota√ß√µes: {q_base:.1f}%)"
        else:
            return f"Presente em {w_base:.1f}% dos clientes da base e {q_base:.1f}% das cota√ß√µes, mas cliente n√£o demonstrou interesse"
    
    def _classify_priority(self, score: float) -> str:
        """Classifica prioridade baseada no score"""
        if score >= 80:
            return "üî¥ ALTA"
        elif score >= 60:
            return "üü° M√âDIA"
        else:
            return "üü¢ BAIXA"
    
    # ==========================================
    # 2. ALERTAS DE INATIVIDADE
    # ==========================================
    
    def calculate_inactivity_alerts(self, vendas_df: pd.DataFrame = None, 
                                   filters: Dict = None) -> pd.DataFrame:
        """
        Calcula alertas de inatividade baseado em 90/365 dias
        
        Args:
            vendas_df: DataFrame de vendas (usa self.vendas_df se n√£o fornecido)
            filters: Filtros adicionais
            
        Returns:
            DataFrame com alertas categorizados e estat√≠sticas
        """
        # Usa DataFrame armazenado se n√£o fornecido
        vendas_data = vendas_df if vendas_df is not None else self.vendas_df
        
        if vendas_data is None or vendas_data.empty:
            return pd.DataFrame({
                'cliente': ['Nenhum cliente'],
                'cod_cliente': [''],
                'category': ['Sem dados'],
                'days_since_last_purchase': [0],
                'last_purchase_date': [''],
                'total_revenue': [0]
            })
        
        print("‚ö†Ô∏è Calculando alertas de inatividade...")
        
        try:
            # Aplica filtros se fornecidos
            vendas_filtered = self._apply_filters(vendas_data, filters) if filters else vendas_data
            
            # Verifica se a coluna de data existe
            date_column = None
            for col in ['data_faturamento', 'data', 'data_venda']:
                if col in vendas_filtered.columns:
                    date_column = col
                    break
            
            if date_column is None:
                print("‚ö†Ô∏è Coluna de data n√£o encontrada, usando data atual")
                # Cria dados sint√©ticos para demonstra√ß√£o
                unique_clients = vendas_filtered['cod_cliente'].unique()[:10]
                return pd.DataFrame({
                    'cliente': [f'Cliente {i}' for i in unique_clients],
                    'cod_cliente': unique_clients,
                    'category': ['Ativo'] * len(unique_clients),
                    'days_since_last_purchase': [30] * len(unique_clients),
                    'last_purchase_date': [self.current_date.strftime('%Y-%m-%d')] * len(unique_clients),
                    'total_revenue': [10000] * len(unique_clients)
                })
            
            # Converte coluna de data
            vendas_filtered[date_column] = pd.to_datetime(vendas_filtered[date_column], errors='coerce')
            
            # Calcula √∫ltima compra por cliente
            ultima_compra = vendas_filtered.groupby('cod_cliente').agg({
                date_column: 'max',
                'cliente': 'first',
                'valor_liquido': 'sum'
            }).reset_index()
            
            ultima_compra.columns = ['cod_cliente', 'last_purchase_date', 'cliente', 'total_revenue']
            
            # Calcula dias desde √∫ltima compra
            ultima_compra['days_since_last_purchase'] = (
                self.current_date - ultima_compra['last_purchase_date']
            ).dt.days
            
            # Categoriza clientes
            def categorize_inactivity(days):
                if days <= 90:
                    return 'Ativo'
                elif days <= 365:
                    return 'Aten√ß√£o'
                else:
                    return 'Cr√≠tico'
            
            ultima_compra['category'] = ultima_compra['days_since_last_purchase'].apply(categorize_inactivity)
            
            # Formata data para string
            ultima_compra['last_purchase_date'] = ultima_compra['last_purchase_date'].dt.strftime('%Y-%m-%d')
            
            # Ordena por dias sem compra (decrescente)
            resultado = ultima_compra.sort_values('days_since_last_purchase', ascending=False)
            
            print(f"‚úÖ An√°lise de inatividade conclu√≠da - {len(resultado)} clientes analisados")
            return resultado
            
        except Exception as e:
            print(f"‚ùå Erro no c√°lculo de inatividade: {e}")
            return pd.DataFrame({
                'cliente': ['Erro no c√°lculo'],
                'cod_cliente': [''],
                'category': ['Erro'],
                'days_since_last_purchase': [0],
                'last_purchase_date': [''],
                'total_revenue': [0]
            })
            'vlr_carteira': 'sum',  # Carteira atual
            'vlr_rol': 'sum',  # Faturamento total
            'material': 'nunique'  # Diversidade de produtos
        }).reset_index()
        
        # Calcula dias desde √∫ltima compra
        ultima_compra['dias_sem_compra'] = (
            self.current_date - ultima_compra['data_faturamento']
        ).dt.days
        
        # Suprime alertas se h√° carteira ativa nos √∫ltimos 30 dias
        carteira_30d = vendas_filtered[
            vendas_filtered['data_faturamento'] >= (self.current_date - timedelta(days=30))
        ].groupby('cod_cliente')['vlr_carteira'].sum()
        
        ultima_compra['carteira_30d'] = ultima_compra['cod_cliente'].map(
            carteira_30d.fillna(0)
        ).fillna(0)
        
        # Classifica alertas
        alertas = []
        for _, cliente in ultima_compra.iterrows():
            dias = cliente['dias_sem_compra']
            carteira = cliente['carteira_30d']
            
            # Suprime alerta se h√° carteira ativa
            if carteira > 0:
                continue
                
            if dias >= 365:
                categoria = "üî¥ CR√çTICO (>365 dias)"
                urgencia = "alta"
            elif dias >= 330:
                categoria = "üü† ATEN√á√ÉO (pr√≥ximo 365 dias)"
                urgencia = "media"
            elif dias >= 90:
                categoria = "üü° MONITORAR (>90 dias)"
                urgencia = "baixa"
            else:
                continue  # N√£o √© alerta
            
            alertas.append({
                'cod_cliente': cliente['cod_cliente'],
                'cliente': cliente['cliente'],
                'dias_sem_compra': int(dias),
                'ultima_compra': cliente['data_faturamento'].strftime('%d/%m/%Y'),
                'categoria': categoria,
                'urgencia': urgencia,
                'faturamento_historico': float(cliente['vlr_rol']),
                'diversidade_produtos': int(cliente['material']),
                'recomendacao': self._generate_inactivity_recommendation(dias, cliente['vlr_rol'])
            })
        
        # Estat√≠sticas dos alertas
        stats = self._calculate_inactivity_stats(alertas, ultima_compra)
        
        # Ordena por urg√™ncia e dias
        urgencia_order = {'alta': 3, 'media': 2, 'baixa': 1}
        alertas.sort(key=lambda x: (urgencia_order[x['urgencia']], x['dias_sem_compra']), reverse=True)
        
        return {
            'alertas': alertas,
            'estatisticas': stats,
            'resumo': self._generate_inactivity_summary(alertas),
            'data_calculo': self.current_date.strftime('%d/%m/%Y %H:%M')
        }
    
    def _generate_inactivity_recommendation(self, dias: int, faturamento: float) -> str:
        """Gera recomenda√ß√£o baseada no perfil de inatividade"""
        if dias >= 365:
            if faturamento > 50000:
                return "Cliente estrat√©gico inativo - contato urgente da ger√™ncia"
            else:
                return "Verificar viabilidade de reativa√ß√£o"
        elif dias >= 330:
            return "Agendamento proativo para evitar inatividade total"
        else:
            return "Acompanhamento comercial de rotina"
    
    def _calculate_inactivity_stats(self, alertas: List[Dict], clientes_total: pd.DataFrame) -> Dict:
        """Calcula estat√≠sticas dos alertas de inatividade"""
        total_clientes = len(clientes_total)
        total_alertas = len(alertas)
        
        # Distribui por categoria
        criticos = sum(1 for a in alertas if a['urgencia'] == 'alta')
        atencao = sum(1 for a in alertas if a['urgencia'] == 'media')
        monitorar = sum(1 for a in alertas if a['urgencia'] == 'baixa')
        
        # Faturamento em risco
        faturamento_risco = sum(a['faturamento_historico'] for a in alertas)
        
        # M√©dia de dias sem compra
        dias_media = np.mean([a['dias_sem_compra'] for a in alertas]) if alertas else 0
        
        return {
            'total_clientes': total_clientes,
            'total_alertas': total_alertas,
            'percentual_alertas': round((total_alertas / total_clientes) * 100, 1) if total_clientes > 0 else 0,
            'distribuicao': {
                'criticos': criticos,
                'atencao': atencao,
                'monitorar': monitorar
            },
            'faturamento_em_risco': float(faturamento_risco),
            'dias_sem_compra_medio': round(dias_media, 1)
        }
    
    def _generate_inactivity_summary(self, alertas: List[Dict]) -> str:
        """Gera resumo executivo dos alertas"""
        if not alertas:
            return "‚úÖ Nenhum alerta de inatividade identificado no per√≠odo"
        
        criticos = sum(1 for a in alertas if a['urgencia'] == 'alta')
        total = len(alertas)
        
        if criticos > 0:
            return f"‚ö†Ô∏è {criticos} cliente(s) em situa√ß√£o cr√≠tica entre {total} alertas totais"
        else:
            return f"üìä {total} cliente(s) requerem acompanhamento preventivo"
    
    # ==========================================
    # 3. AN√ÅLISE DE SAZONALIDADE
    # ==========================================
    
    def analyze_seasonality(self, vendas_df: pd.DataFrame, 
                           filters: Dict = None) -> Dict:
        """
        An√°lise estat√≠stica de sazonalidade das vendas
        
        Returns:
            Dict com decomposi√ß√£o temporal e insights de sazonalidade
        """
        print("üìà Analisando sazonalidade das vendas...")
        
        # Aplica filtros se fornecidos
        vendas_filtered = self._apply_filters(vendas_df, filters) if filters else vendas_df
        
        if vendas_filtered.empty:
            return {"error": "Nenhum dado de vendas encontrado"}
        
        # Prepara s√©rie temporal mensal
        vendas_monthly = self._prepare_monthly_series(vendas_filtered)
        
        if vendas_monthly.empty:
            return {"error": "Dados insuficientes para an√°lise de sazonalidade"}
        
        # Decomposi√ß√£o de s√©rie temporal
        decomposition = self._decompose_time_series(vendas_monthly)
        
        # An√°lise de concentra√ß√£o 1¬∫ vs 2¬∫ semestre
        concentration_analysis = self._analyze_semester_concentration(vendas_monthly)
        
        # An√°lise estat√≠stica de signific√¢ncia
        statistical_tests = self._perform_seasonality_tests(vendas_monthly)
        
        # Padr√µes mensais
        monthly_patterns = self._analyze_monthly_patterns(vendas_monthly)
        
        return {
            'periodo_analise': f"{vendas_monthly.index.min().strftime('%m/%Y')} a {vendas_monthly.index.max().strftime('%m/%Y')}",
            'decomposicao_temporal': decomposition,
            'concentracao_semestral': concentration_analysis,
            'testes_estatisticos': statistical_tests,
            'padroes_mensais': monthly_patterns,
            'insights': self._generate_seasonality_insights(concentration_analysis, statistical_tests)
        }
    
    def _prepare_monthly_series(self, vendas_df: pd.DataFrame) -> pd.DataFrame:
        """Prepara s√©rie temporal mensal"""
        if 'data_faturamento' not in vendas_df.columns:
            return pd.DataFrame()
        
        # Converte para datetime se necess√°rio
        vendas_df['data_faturamento'] = pd.to_datetime(vendas_df['data_faturamento'])
        
        # Agrupa por m√™s
        monthly_data = vendas_df.groupby(
            vendas_df['data_faturamento'].dt.to_period('M')
        ).agg({
            'vlr_entrada': 'sum',
            'vlr_carteira': 'sum', 
            'vlr_rol': 'sum'
        })
        
        # Remove valores nulos
        monthly_data = monthly_data.fillna(0)
        
        return monthly_data
    
    def _decompose_time_series(self, monthly_data: pd.DataFrame) -> Dict:
        """Decomposi√ß√£o STL da s√©rie temporal"""
        try:
            from statsmodels.tsa.seasonal import seasonal_decompose
            
            # Usa vlr_rol como s√©rie principal
            if 'vlr_rol' not in monthly_data.columns:
                return {"error": "Coluna vlr_rol n√£o encontrada"}
            
            ts = monthly_data['vlr_rol']
            
            # Decomposi√ß√£o aditiva (m√≠nimo 24 observa√ß√µes)
            if len(ts) >= 24:
                decomp = seasonal_decompose(ts, model='additive', period=12)
                
                return {
                    'trend': decomp.trend.dropna().to_dict(),
                    'seasonal': decomp.seasonal.to_dict(),
                    'residual': decomp.resid.dropna().to_dict(),
                    'seasonal_strength': float(np.var(decomp.seasonal) / np.var(ts)) if np.var(ts) > 0 else 0
                }
            else:
                # An√°lise simplificada para s√©ries curtas
                monthly_avg = ts.groupby(ts.index.month).mean()
                seasonal_coef = (monthly_avg - monthly_avg.mean()) / monthly_avg.mean() * 100
                
                return {
                    'seasonal_coefficients': seasonal_coef.to_dict(),
                    'seasonal_strength': float(seasonal_coef.std() / 100),
                    'observacao': "S√©rie muito curta para decomposi√ß√£o completa"
                }
                
        except ImportError:
            # Fallback sem statsmodels
            monthly_avg = monthly_data['vlr_rol'].groupby(monthly_data.index.month).mean()
            return {
                'monthly_averages': monthly_avg.to_dict(),
                'observacao': "Decomposi√ß√£o completa requer statsmodels"
            }
    
    def _analyze_semester_concentration(self, monthly_data: pd.DataFrame) -> Dict:
        """Analisa concentra√ß√£o 1¬∫ vs 2¬∫ semestre"""
        yearly_data = []
        
        # Agrupa por ano
        for year in monthly_data.index.year.unique():
            year_data = monthly_data[monthly_data.index.year == year]
            
            # 1¬∫ semestre (Jan-Jul)
            primeiro_sem = year_data[year_data.index.month <= 7]['vlr_rol'].sum()
            
            # 2¬∫ semestre (Ago-Dez)
            segundo_sem = year_data[year_data.index.month > 7]['vlr_rol'].sum()
            
            total_ano = primeiro_sem + segundo_sem
            
            if total_ano > 0:
                yearly_data.append({
                    'ano': year,
                    'primeiro_semestre': float(primeiro_sem),
                    'segundo_semestre': float(segundo_sem),
                    'percentual_primeiro': float(primeiro_sem / total_ano * 100),
                    'percentual_segundo': float(segundo_sem / total_ano * 100)
                })
        
        if not yearly_data:
            return {"error": "Dados insuficientes para an√°lise semestral"}
        
        # M√©dias
        avg_primeiro = np.mean([y['percentual_primeiro'] for y in yearly_data])
        avg_segundo = np.mean([y['percentual_segundo'] for y in yearly_data])
        
        # Intervalos de confian√ßa
        if len(yearly_data) > 1:
            primeiro_values = [y['percentual_primeiro'] for y in yearly_data]
            ic_primeiro = self._confidence_interval_mean(primeiro_values)
            
            segundo_values = [y['percentual_segundo'] for y in yearly_data]
            ic_segundo = self._confidence_interval_mean(segundo_values)
        else:
            ic_primeiro = [avg_primeiro, avg_primeiro]
            ic_segundo = [avg_segundo, avg_segundo]
        
        return {
            'detalhes_anuais': yearly_data,
            'medias': {
                'primeiro_semestre': round(avg_primeiro, 1),
                'segundo_semestre': round(avg_segundo, 1)
            },
            'intervalos_confianca': {
                'primeiro_semestre': [round(ic_primeiro[0], 1), round(ic_primeiro[1], 1)],
                'segundo_semestre': [round(ic_segundo[0], 1), round(ic_segundo[1], 1)]
            }
        }
    
    def _perform_seasonality_tests(self, monthly_data: pd.DataFrame) -> Dict:
        """Realiza testes estat√≠sticos de sazonalidade"""
        ts = monthly_data['vlr_rol']
        
        if len(ts) < 12:
            return {"error": "Dados insuficientes para testes estat√≠sticos"}
        
        # Teste de Kruskal-Wallis por m√™s
        monthly_groups = [
            ts[ts.index.month == month].values 
            for month in range(1, 13) 
            if len(ts[ts.index.month == month]) > 0
        ]
        
        # Remove grupos vazios
        monthly_groups = [group for group in monthly_groups if len(group) > 0]
        
        if len(monthly_groups) >= 3:
            try:
                kw_stat, kw_pvalue = stats.kruskal(*monthly_groups)
                
                return {
                    'kruskal_wallis': {
                        'estatistica': float(kw_stat),
                        'p_value': float(kw_pvalue),
                        'significativo': kw_pvalue < 0.05,
                        'interpretacao': "Sazonalidade significativa detectada" if kw_pvalue < 0.05 else "N√£o h√° evid√™ncia de sazonalidade"
                    }
                }
            except:
                return {"observacao": "N√£o foi poss√≠vel realizar teste estat√≠stico"}
        else:
            return {"observacao": "Dados insuficientes para teste de sazonalidade"}
    
    def _analyze_monthly_patterns(self, monthly_data: pd.DataFrame) -> Dict:
        """Analisa padr√µes mensais detalhados"""
        monthly_stats = monthly_data.groupby(monthly_data.index.month).agg({
            'vlr_rol': ['mean', 'std', 'count']
        }).round(2)
        
        # Flatten column names
        monthly_stats.columns = ['media', 'desvio', 'observacoes']
        
        # Identifica picos e vales
        media_overall = monthly_stats['media'].mean()
        monthly_stats['percentual_media'] = (monthly_stats['media'] / media_overall * 100).round(1)
        
        # Classifica meses
        monthly_stats['classificacao'] = monthly_stats['percentual_media'].apply(
            lambda x: 'PICO' if x > 115 else 'VALE' if x < 85 else 'NORMAL'
        )
        
        meses_nomes = {
            1: 'Janeiro', 2: 'Fevereiro', 3: 'Mar√ßo', 4: 'Abril',
            5: 'Maio', 6: 'Junho', 7: 'Julho', 8: 'Agosto',
            9: 'Setembro', 10: 'Outubro', 11: 'Novembro', 12: 'Dezembro'
        }
        
        # Adiciona nomes dos meses
        monthly_stats['mes_nome'] = monthly_stats.index.map(meses_nomes)
        
        return monthly_stats.to_dict('index')
    
    def _generate_seasonality_insights(self, concentration: Dict, tests: Dict) -> List[str]:
        """Gera insights baseados na an√°lise de sazonalidade"""
        insights = []
        
        if 'medias' in concentration:
            primeiro = concentration['medias']['primeiro_semestre']
            segundo = concentration['medias']['segundo_semestre']
            
            if primeiro > 55:
                insights.append(f"üìä Concentra√ß√£o no 1¬∫ semestre: {primeiro:.1f}% das vendas ocorrem at√© julho")
            elif segundo > 55:
                insights.append(f"üìä Concentra√ß√£o no 2¬∫ semestre: {segundo:.1f}% das vendas ocorrem de agosto a dezembro")
            else:
                insights.append("üìä Distribui√ß√£o equilibrada entre semestres")
        
        if 'kruskal_wallis' in tests:
            if tests['kruskal_wallis']['significativo']:
                insights.append("üìà Padr√£o sazonal estatisticamente significativo identificado")
            else:
                insights.append("üìà Vendas n√£o apresentam sazonalidade estatisticamente significativa")
        
        return insights
    
    # ==========================================
    # 4. AN√ÅLISE DE DEMANDAS DE COTA√á√ÉO
    # ==========================================
    
    def analyze_quotation_demand(self, cotacoes_df: pd.DataFrame, 
                                vendas_df: pd.DataFrame,
                                filters: Dict = None) -> Dict:
        """
        An√°lise da demanda de cota√ß√µes e esfor√ßo da equipe
        
        Returns:
            Dict com an√°lise temporal de cota√ß√µes e m√©tricas de efici√™ncia
        """
        print("üìã Analisando demanda de cota√ß√µes...")
        
        # Aplica filtros
        cotacoes_filtered = self._apply_filters(cotacoes_df, filters, is_cotacoes=True) if filters else cotacoes_df
        vendas_filtered = self._apply_filters(vendas_df, filters) if filters else vendas_df
        
        if cotacoes_filtered.empty:
            return {"error": "Nenhum dado de cota√ß√£o encontrado"}
        
        # S√©rie temporal mensal de cota√ß√µes
        monthly_quotations = self._prepare_quotation_monthly_series(cotacoes_filtered)
        
        # M√©tricas de esfor√ßo
        effort_metrics = self._calculate_effort_metrics(cotacoes_filtered, vendas_filtered)
        
        # Taxa de convers√£o
        conversion_analysis = self._analyze_conversion_rates(cotacoes_filtered, vendas_filtered)
        
        # Sazonalidade das cota√ß√µes
        quotation_seasonality = self._analyze_quotation_seasonality(monthly_quotations)
        
        # Insights de performance
        performance_insights = self._generate_quotation_insights(effort_metrics, conversion_analysis)
        
        return {
            'periodo_analise': self._get_period_description(filters),
            'serie_temporal_mensal': monthly_quotations.to_dict('index') if not monthly_quotations.empty else {},
            'metricas_esforco': effort_metrics,
            'analise_conversao': conversion_analysis,
            'sazonalidade_cotacoes': quotation_seasonality,
            'insights_performance': performance_insights
        }
    
    def _prepare_quotation_monthly_series(self, cotacoes_df: pd.DataFrame) -> pd.DataFrame:
        """Prepara s√©rie temporal mensal de cota√ß√µes"""
        if 'data' not in cotacoes_df.columns:
            return pd.DataFrame()
        
        # Converte para datetime
        cotacoes_df['data'] = pd.to_datetime(cotacoes_df['data'])
        
        # Agrupa por m√™s
        monthly_quotes = cotacoes_df.groupby(
            cotacoes_df['data'].dt.to_period('M')
        ).agg({
            'numero_cotacao': 'nunique',  # N√∫mero de cota√ß√µes √∫nicas
            'preco_liq_total': 'sum',     # Valor total cotado
            'cod_cliente': 'nunique'      # Clientes √∫nicos que cotaram
        }).fillna(0)
        
        # Renomeia colunas
        monthly_quotes.columns = ['qtd_cotacoes', 'valor_cotado', 'clientes_unicos']
        
        return monthly_quotes
    
    def _calculate_effort_metrics(self, cotacoes_df: pd.DataFrame, vendas_df: pd.DataFrame) -> Dict:
        """Calcula m√©tricas de esfor√ßo da equipe"""
        # Total de cota√ß√µes e clientes ativos
        total_cotacoes = cotacoes_df['numero_cotacao'].nunique() if 'numero_cotacao' in cotacoes_df.columns else 0
        clientes_cotaram = cotacoes_df['cod_cliente'].nunique() if not cotacoes_df.empty else 0
        clientes_compraram = vendas_df['cod_cliente'].nunique() if not vendas_df.empty else 0
        
        # √çndice de esfor√ßo relativo
        indice_esforco = (total_cotacoes / max(clientes_cotaram, 1)) if clientes_cotaram > 0 else 0
        
        # Valor m√©dio por cota√ß√£o
        if not cotacoes_df.empty and 'preco_liq_total' in cotacoes_df.columns:
            valor_medio_cotacao = cotacoes_df['preco_liq_total'].mean()
        else:
            valor_medio_cotacao = 0
        
        # Distribui√ß√£o de cota√ß√µes por cliente
        if not cotacoes_df.empty and 'cod_cliente' in cotacoes_df.columns:
            cotacoes_por_cliente = cotacoes_df.groupby('cod_cliente')['numero_cotacao'].nunique()
            
            quartis = np.percentile(cotacoes_por_cliente.values, [25, 50, 75])
        else:
            quartis = [0, 0, 0]
        
        return {
            'total_cotacoes': int(total_cotacoes),
            'clientes_cotaram': int(clientes_cotaram),
            'clientes_compraram': int(clientes_compraram),
            'indice_esforco_relativo': round(indice_esforco, 2),
            'valor_medio_cotacao': float(valor_medio_cotacao),
            'distribuicao_por_cliente': {
                'q1': float(quartis[0]),
                'mediana': float(quartis[1]),
                'q3': float(quartis[2])
            }
        }
    
    def _analyze_conversion_rates(self, cotacoes_df: pd.DataFrame, vendas_df: pd.DataFrame) -> Dict:
        """Analisa taxas de convers√£o cota√ß√£o ‚Üí pedido"""
        if cotacoes_df.empty or vendas_df.empty:
            return {"error": "Dados insuficientes para an√°lise de convers√£o"}
        
        # Clientes que cotaram
        clientes_cotaram = set(cotacoes_df['cod_cliente'].unique())
        
        # Clientes que compraram
        clientes_compraram = set(vendas_df['cod_cliente'].unique())
        
        # Convers√£o de clientes
        clientes_converteram = clientes_cotaram & clientes_compraram
        taxa_conversao_clientes = (len(clientes_converteram) / len(clientes_cotaram)) * 100 if clientes_cotaram else 0
        
        # Convers√£o por material (mais complexo - aproxima√ß√£o)
        materiais_cotados = set(cotacoes_df['material'].unique()) if 'material' in cotacoes_df.columns else set()
        materiais_comprados = set(vendas_df['material'].unique()) if 'material' in vendas_df.columns else set()
        materiais_converteram = materiais_cotados & materiais_comprados
        
        taxa_conversao_materiais = (len(materiais_converteram) / len(materiais_cotados)) * 100 if materiais_cotados else 0
        
        # Valor de convers√£o
        valor_cotado_total = cotacoes_df['preco_liq_total'].sum() if 'preco_liq_total' in cotacoes_df.columns else 0
        valor_vendido_total = vendas_df['vlr_rol'].sum() if 'vlr_rol' in vendas_df.columns else 0
        
        return {
            'taxa_conversao_clientes': round(taxa_conversao_clientes, 1),
            'taxa_conversao_materiais': round(taxa_conversao_materiais, 1),
            'clientes_cotaram': len(clientes_cotaram),
            'clientes_converteram': len(clientes_converteram),
            'materiais_cotados': len(materiais_cotados),
            'materiais_converteram': len(materiais_converteram),
            'valor_cotado': float(valor_cotado_total),
            'valor_convertido': float(valor_vendido_total),
            'eficiencia_valor': round((valor_vendido_total / valor_cotado_total) * 100, 1) if valor_cotado_total > 0 else 0
        }
    
    def _analyze_quotation_seasonality(self, monthly_quotes: pd.DataFrame) -> Dict:
        """Analisa sazonalidade das cota√ß√µes"""
        if monthly_quotes.empty:
            return {"error": "Dados insuficientes"}
        
        # Padr√£o mensal
        monthly_avg = monthly_quotes.groupby(monthly_quotes.index.month).mean()
        
        # Identifica meses de pico e vale
        overall_avg = monthly_avg['qtd_cotacoes'].mean()
        
        picos = monthly_avg[monthly_avg['qtd_cotacoes'] > overall_avg * 1.2].index.tolist()
        vales = monthly_avg[monthly_avg['qtd_cotacoes'] < overall_avg * 0.8].index.tolist()
        
        meses_nomes = {
            1: 'Janeiro', 2: 'Fevereiro', 3: 'Mar√ßo', 4: 'Abril',
            5: 'Maio', 6: 'Junho', 7: 'Julho', 8: 'Agosto',
            9: 'Setembro', 10: 'Outubro', 11: 'Novembro', 12: 'Dezembro'
        }
        
        return {
            'media_mensal': monthly_avg.to_dict('index'),
            'meses_pico': [meses_nomes[m] for m in picos],
            'meses_vale': [meses_nomes[m] for m in vales],
            'coeficiente_variacao': float(monthly_avg['qtd_cotacoes'].std() / monthly_avg['qtd_cotacoes'].mean()) if monthly_avg['qtd_cotacoes'].mean() > 0 else 0
        }
    
    def _generate_quotation_insights(self, effort_metrics: Dict, conversion_analysis: Dict) -> List[str]:
        """Gera insights de performance das cota√ß√µes"""
        insights = []
        
        # Insights de esfor√ßo
        if effort_metrics['indice_esforco_relativo'] > 3:
            insights.append(f"‚ö†Ô∏è Alto esfor√ßo: {effort_metrics['indice_esforco_relativo']:.1f} cota√ß√µes por cliente")
        elif effort_metrics['indice_esforco_relativo'] < 1.5:
            insights.append(f"‚úÖ Esfor√ßo otimizado: {effort_metrics['indice_esforco_relativo']:.1f} cota√ß√µes por cliente")
        
        # Insights de convers√£o
        if 'taxa_conversao_clientes' in conversion_analysis:
            taxa = conversion_analysis['taxa_conversao_clientes']
            if taxa > 70:
                insights.append(f"üéØ Excelente convers√£o de clientes: {taxa:.1f}%")
            elif taxa < 40:
                insights.append(f"üìà Oportunidade de melhoria na convers√£o: {taxa:.1f}%")
        
        return insights
    
    # ==========================================
    # M√âTODOS AUXILIARES
    # ==========================================
    
    def _apply_filters(self, df: pd.DataFrame, filters: Dict, is_cotacoes: bool = False) -> pd.DataFrame:
        """Aplica filtros aos dados"""
        if df.empty or not filters:
            return df
            
        df_filtered = df.copy()
        
        # Filtro de ano
        if filters.get('ano'):
            date_col = 'data' if is_cotacoes else 'data_faturamento'
            if date_col in df_filtered.columns:
                df_filtered[date_col] = pd.to_datetime(df_filtered[date_col])
                if isinstance(filters['ano'], list) and len(filters['ano']) == 2:
                    start_year, end_year = filters['ano']
                    df_filtered = df_filtered[
                        (df_filtered[date_col].dt.year >= start_year) &
                        (df_filtered[date_col].dt.year <= end_year)
                    ]
        
        # Filtro de canal (apenas para vendas)
        if not is_cotacoes and filters.get('canal') and 'canal_distribuicao' in df_filtered.columns:
            if isinstance(filters['canal'], list):
                df_filtered = df_filtered[df_filtered['canal_distribuicao'].isin(filters['canal'])]
        
        # Filtro de cliente
        if filters.get('cliente') and 'cod_cliente' in df_filtered.columns:
            if isinstance(filters['cliente'], list):
                df_filtered = df_filtered[df_filtered['cod_cliente'].isin(filters['cliente'])]
        
        return df_filtered
    
    def _binomial_confidence_interval(self, successes: int, trials: int, confidence: float = 0.95) -> Tuple[float, float]:
        """Calcula intervalo de confian√ßa binomial"""
        if trials == 0:
            return (0.0, 0.0)
        
        # M√©todo Wilson
        z = stats.norm.ppf((1 + confidence) / 2)
        p = successes / trials
        
        denominator = 1 + z**2 / trials
        center = (p + z**2 / (2 * trials)) / denominator
        margin = z * np.sqrt((p * (1 - p) + z**2 / (4 * trials)) / trials) / denominator
        
        lower = max(0, (center - margin) * 100)
        upper = min(100, (center + margin) * 100)
        
        return (lower, upper)
    
    def _confidence_interval_mean(self, values: List[float], confidence: float = 0.95) -> Tuple[float, float]:
        """Calcula intervalo de confian√ßa para m√©dia"""
        if len(values) < 2:
            return (values[0] if values else 0, values[0] if values else 0)
        
        mean = np.mean(values)
        sem = stats.sem(values)  # Standard error of mean
        
        # t-distribution para amostras pequenas
        degrees_freedom = len(values) - 1
        t_value = stats.t.ppf((1 + confidence) / 2, degrees_freedom)
        
        margin = t_value * sem
        
        return (mean - margin, mean + margin)
    
    def _get_period_description(self, filters: Dict) -> str:
        """Gera descri√ß√£o textual do per√≠odo analisado"""
        if not filters:
            return "Per√≠odo completo dispon√≠vel"
        
        parts = []
        
        if filters.get('ano'):
            if isinstance(filters['ano'], list) and len(filters['ano']) == 2:
                parts.append(f"Anos: {filters['ano'][0]}-{filters['ano'][1]}")
            else:
                parts.append(f"Ano: {filters['ano']}")
        
        if filters.get('mes'):
            if isinstance(filters['mes'], list) and len(filters['mes']) == 2:
                parts.append(f"Meses: {filters['mes'][0]}-{filters['mes'][1]}")
        
        return " | ".join(parts) if parts else "Per√≠odo filtrado"
    
    def _generate_gap_recommendations(self, gaps: List[Dict]) -> List[str]:
        """Gera recomenda√ß√µes baseadas nos gaps identificados"""
        if not gaps:
            return ["‚úÖ Cliente possui mix alinhado com a base compar√°vel"]
        
        recommendations = []
        
        # Top 3 oportunidades
        top_gaps = gaps[:3]
        
        for gap in top_gaps:
            material = gap['material']
            score = gap['opportunity_score']
            w_base = gap['w_penetracao_base']
            
            if gap['cliente_cotacao']:
                rec = f"üéØ {material}: Cliente cotou mas n√£o comprou (oportunidade {score:.0f}pts)"
            else:
                rec = f"üîç {material}: Presente em {w_base:.0f}% da base, mas cliente n√£o demonstrou interesse"
            
            recommendations.append(rec)
        
        # Recomenda√ß√£o geral
        if len(gaps) > 3:
            recommendations.append(f"üìä Total de {len(gaps)} oportunidades identificadas")
        
        return recommendations
